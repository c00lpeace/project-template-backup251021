# _*_ coding: utf-8 _*_
"""
Program Upload Service for handling program file upload workflow.

Phase 3 ë¦¬íŒ©í† ë§ (2025-11-06):
- FileValidationService, FileStorageService í†µí•©
- ëª…í™•í•œ ë³€ìˆ˜ëª… ì ìš© (pgm_ladder_zip_file, pgm_template_file)
- í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •
- DocumentServiceì˜ ìƒˆ ë©”ì„œë“œ ì‚¬ìš©
- íŠ¸ëœì­ì…˜ ê²½ê³„ ëª…í™•í™”
"""
import logging
import io
import zipfile
from typing import Dict, List, Optional
from pathlib import Path
from datetime import datetime

from fastapi import UploadFile
from sqlalchemy.orm import Session

from ai_backend.config.simple_settings import settings
from ai_backend.api.services.sequence_service import SequenceService
from ai_backend.api.services.file_validation_service import FileValidationService
from ai_backend.api.services.file_storage_service import FileStorageService
from ai_backend.api.services.document_service import DocumentService
from ai_backend.api.services.template_service import TemplateService
from ai_backend.api.services.program_service import ProgramService
from ai_backend.database.crud.program_crud import ProgramCrud
from ai_backend.types.response.exceptions import HandledException
from ai_backend.types.response.response_code import ResponseCode

logger = logging.getLogger(__name__)


class ProgramUploadService:
    """
    í”„ë¡œê·¸ë¨ íŒŒì¼ ì—…ë¡œë“œ í†µí•© ì„œë¹„ìŠ¤ (Phase 3 ë¦¬íŒ©í† ë§)
    
    ì›Œí¬í”Œë¡œìš°:
    Phase 1: ê²€ì¦ (DB íŠ¸ëœì­ì…˜ ì™¸ë¶€)
    Step 1-2: ë ˆë” ZIP íƒ€ì…/í¬ê¸° ê²€ì¦
    Step 3:   ZIP êµ¬ì¡° ê²€ì¦ (ì†ìƒ ì—¬ë¶€, íŒŒì¼ ëª©ë¡ë§Œ)
    Step 4-5: í…œí”Œë¦¿ íƒ€ì…/í¬ê¸° ê²€ì¦
    Step 6:   í…œí”Œë¦¿ êµ¬ì¡° ê²€ì¦ (í•„ìˆ˜ ì»¬ëŸ¼, Logic ID ì¶”ì¶œ)
    Step 7:   ë§¤ì¹­ ê²€ì¦ (í…œí”Œë¦¿ Logic ID vs ZIP íŒŒì¼ ëª©ë¡)
    Step 8:   ë§¤ì¹­ëœ CSVë§Œ êµ¬ì¡° ê²€ì¦ (ë©”ëª¨ë¦¬) â­ Phase 1.5 ì‹ ê·œ
    
    Phase 2: íŒŒì¼ ì €ì¥ (DB íŠ¸ëœì­ì…˜ ì™¸ë¶€)
    Step 9:  ë ˆë” ZIP í•„í„°ë§
    Step 10: ë ˆë” ZIP ì €ì¥ ë° ì••ì¶• í•´ì œ (FileStorageService)
    Step 11: í…œí”Œë¦¿ íŒŒì¼ ì €ì¥ (FileStorageService)
    
    Phase 3: DB ì €ì¥ (íŠ¸ëœì­ì…˜ ì‹œì‘)
    Step 12: ë ˆë” CSV ë¬¸ì„œ ë ˆì½”ë“œ ì¼ê´„ ìƒì„± (DocumentService)
    Step 13: í…œí”Œë¦¿ ë¬¸ì„œ ë ˆì½”ë“œ ìƒì„± + ìë™ íŒŒì‹± (DocumentService)
    Step 14: í”„ë¡œê·¸ë¨ ë ˆì½”ë“œ ìƒì„± (ProgramService)
    Step 15: ì»¤ë°‹
    """
    
    def __init__(
        self,
        db: Session,
        sequence_service: SequenceService,
        file_validation_service: FileValidationService,
        file_storage_service: FileStorageService,
        document_service: DocumentService,
        template_service: TemplateService,
        program_service: ProgramService
    ):
        """
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            sequence_service: PGM_ID ìƒì„± ì„œë¹„ìŠ¤
            file_validation_service: íŒŒì¼ ê²€ì¦ ì„œë¹„ìŠ¤ (Phase 1 ì‹ ê·œ)
            file_storage_service: íŒŒì¼ ì €ì¥ ì„œë¹„ìŠ¤ (Phase 1 ì‹ ê·œ)
            document_service: ë¬¸ì„œ DB ì„œë¹„ìŠ¤ (Phase 2 ë¦¬íŒ©í† ë§)
            template_service: í…œí”Œë¦¿ ì„œë¹„ìŠ¤
            program_service: í”„ë¡œê·¸ë¨ ì„œë¹„ìŠ¤
        """
        self.db = db
        self.settings = settings  # í™˜ê²½ë³€ìˆ˜ ì£¼ì…
        self.sequence_service = sequence_service
        self.file_validation_service = file_validation_service
        self.file_storage_service = file_storage_service
        self.document_service = document_service
        self.template_service = template_service
        self.program_service = program_service
        self.program_crud = ProgramCrud(db)
    
    def upload_program_with_files(
        self,
        pgm_name: str,
        pgm_ladder_zip_file: UploadFile,  # ëª…í™•í•œ ë³€ìˆ˜ëª…
        pgm_template_file: UploadFile,    # ëª…í™•í•œ ë³€ìˆ˜ëª…
        create_user: str,
        pgm_version: Optional[str] = None,
        description: Optional[str] = None,
        notes: Optional[str] = None
    ) -> Dict:
        """
        í”„ë¡œê·¸ë¨ íŒŒì¼ ì—…ë¡œë“œ ë° ìƒì„± (ì „ì²´ ì›Œí¬í”Œë¡œìš°)
        
        Phase 3 ë¦¬íŒ©í† ë§ (2025-11-06):
        - ëª…í™•í•œ ë³€ìˆ˜ëª… ì‚¬ìš©
        - ìƒˆ ì„œë¹„ìŠ¤ í†µí•© (FileValidationService, FileStorageService)
        - DocumentService ìƒˆ ë©”ì„œë“œ ì‚¬ìš©
        - íŠ¸ëœì­ì…˜ ê²½ê³„ ëª…í™•í™”
        
        Args:
            pgm_name: í”„ë¡œê·¸ë¨ ëª…ì¹­
            pgm_ladder_zip_file: ë ˆë” CSV íŒŒì¼ë“¤ì´ ì••ì¶•ëœ ZIP
            pgm_template_file: í•„ìˆ˜ íŒŒì¼ ëª©ë¡ì´ ê¸°ì¬ëœ í…œí”Œë¦¿ íŒŒì¼
            create_user: ìƒì„±ì
            pgm_version: í”„ë¡œê·¸ë¨ ë²„ì „ (ì„ íƒ)
            description: í”„ë¡œê·¸ë¨ ì„¤ëª… (ì„ íƒ)
            notes: ë¹„ê³  (ì„ íƒ)
            
        Returns:
            {
                'program': Program,
                'pgm_id': str,
                'validation_result': Dict,
                'saved_files': Dict,
                'summary': Dict,
                'message': str
            }
        """
        saved_file_paths = []  # ë¡¤ë°±ìš©
        
        try:
            # ======================================
            # Phase 1: ê²€ì¦ (DB íŠ¸ëœì­ì…˜ ì™¸ë¶€)
            # ======================================
            
            # 0. PGM_ID ìë™ ìƒì„±
            pgm_id = self.sequence_service.generate_pgm_id()
            logger.info(f"âœ… [Step 0] PGM_ID ìë™ ìƒì„±: {pgm_id}")
            
            # 1. ë ˆë” ZIP íŒŒì¼ íƒ€ì…/í¬ê¸° ê²€ì¦ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
            self.file_validation_service.validate_ladder_zip_file_type(
                pgm_ladder_zip_file
            )
            self.file_validation_service.validate_ladder_zip_file_size(
                pgm_ladder_zip_file
            )
            logger.info(
                f"âœ… [Step 1] ë ˆë” ZIP íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {pgm_ladder_zip_file.filename}"
            )
            
            # 2. í…œí”Œë¦¿ íŒŒì¼ íƒ€ì…/í¬ê¸° ê²€ì¦ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜)
            self.file_validation_service.validate_template_file_type(
                pgm_template_file
            )
            self.file_validation_service.validate_template_file_size(
                pgm_template_file
            )
            logger.info(
                f"âœ… [Step 2] í…œí”Œë¦¿ íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {pgm_template_file.filename}"
            )
            
            # 3. í…œí”Œë¦¿ êµ¬ì¡° ê²€ì¦ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ í•„ìˆ˜ ì»¬ëŸ¼)
            template_structure = self.file_validation_service.validate_template_file_structure(
                pgm_template_file
            )
            logger.info(
                f"âœ… [Step 3] í…œí”Œë¦¿ êµ¬ì¡° ê²€ì¦ ì™„ë£Œ: "
                f"{len(template_structure['logic_ids'])}ê°œ Logic ID"
            )
            
            # 4. ZIP êµ¬ì¡° ê²€ì¦
            zip_structure = self.file_validation_service.validate_ladder_zip_structure(
                pgm_ladder_zip_file
            )
            logger.info(
                f"âœ… [Step 4] ZIP êµ¬ì¡° ê²€ì¦ ì™„ë£Œ: "
                f"{len(zip_structure['file_list'])}ê°œ íŒŒì¼"
            )
            
            # 5. ë ˆë” íŒŒì¼ ë§¤ì¹­ ê²€ì¦
            validation_result = self.file_validation_service.validate_ladder_files_match(
                required_files=template_structure['logic_ids'],
                actual_files=zip_structure['file_list']
            )
            
            if not validation_result['validation_passed']:
                missing_files_str = ', '.join(validation_result['missing_files'])
                logger.error(
                    f"âŒ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: pgm_id={pgm_id}, "
                    f"ëˆ„ë½ íŒŒì¼={missing_files_str}"
                )
                raise HandledException(
                    ResponseCode.INVALID_DATA_FORMAT,
                    msg=f"í•„ìˆ˜ ë ˆë” íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_files_str}"
                )
            
            logger.info(
                f"âœ… [Step 7] ë ˆë” íŒŒì¼ ë§¤ì¹­ ê²€ì¦ ì™„ë£Œ: "
                f"{len(validation_result['matched_files'])}ê°œ ì¼ì¹˜"
            )
            
            # 8. ë§¤ì¹­ëœ ë ˆë” CSV íŒŒì¼ êµ¬ì¡° ê²€ì¦ (ë©”ëª¨ë¦¬) - Phase 1.5 ì‹ ê·œ
            csv_structure_validation_result = self.file_validation_service.validate_matched_ladder_csv_structures_in_memory(
                ladder_zip_file=pgm_ladder_zip_file,
                matched_files=validation_result['matched_files']
            )
            
            logger.info(
                f"âœ… [Step 8] ë ˆë” CSV êµ¬ì¡° ê²€ì¦ ì™„ë£Œ: "
                f"{csv_structure_validation_result['validated_count']}ê°œ íŒŒì¼ í†µê³¼"
            )
            
            # ======================================
            # Phase 2: íŒŒì¼ ì €ì¥ (DB íŠ¸ëœì­ì…˜ ì™¸ë¶€)
            # ======================================
            
            # 9. ë ˆë” ZIP í•„í„°ë§ (í•„ìš”í•œ íŒŒì¼ë§Œ)
            filtered_ladder_zip_bytes = self._filter_ladder_zip(
                pgm_ladder_zip_file,
                validation_result['matched_files']
            )
            logger.info(f"âœ… [Step 9] ë ˆë” ZIP í•„í„°ë§ ì™„ë£Œ")
            
            # 10. ë ˆë” ZIP ì €ì¥ ë° ì••ì¶• í•´ì œ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ê²½ë¡œ)
            ladder_zip_extract_result = self.file_storage_service.save_and_extract_ladder_zip(
                ladder_zip_bytes=filtered_ladder_zip_bytes,
                pgm_id=pgm_id,
                original_filename=pgm_ladder_zip_file.filename
            )
            
            # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ê¸°ë¡ (ë¡¤ë°±ìš©)
            saved_file_paths.extend([
                f['path'] for f in ladder_zip_extract_result['extracted_ladder_files']
            ])
            if ladder_zip_extract_result.get('original_zip'):
                saved_file_paths.append(
                    ladder_zip_extract_result['original_zip']['path']
                )
            
            logger.info(
                f"âœ… [Step 10] ë ˆë” íŒŒì¼ ì €ì¥ ì™„ë£Œ: "
                f"{len(ladder_zip_extract_result['extracted_ladder_files'])}ê°œ"
            )
            
            # 11. í…œí”Œë¦¿ íŒŒì¼ ì €ì¥ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ê²½ë¡œ)
            template_save_result = self.file_storage_service.save_template_file(
                template_file=pgm_template_file,
                pgm_id=pgm_id
            )
            saved_file_paths.append(template_save_result['file_path'])
            
            logger.info(f"âœ… [Step 11] í…œí”Œë¦¿ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            
            # ======================================
            # Phase 3: DB ì €ì¥ (íŠ¸ëœì­ì…˜ ì‹œì‘)
            # ======================================
            
            # 12. ë ˆë” CSV ë¬¸ì„œ ë ˆì½”ë“œ ì¼ê´„ ìƒì„±
            pgm_ladder_csv_documents_data = [
                {
                    'document_name': file_info['filename'],
                    'original_filename': file_info['filename'],
                    'file_key': f"{pgm_id}/{self.settings.pgm_ladder_dir_name}/{file_info['filename']}",
                    'upload_path': str(file_info['path']),
                    'file_size': file_info['size'],
                    'pgm_id': pgm_id,
                    'user_id': create_user,
                    'is_public': False,
                    'metadata': {
                        'file_hash': file_info.get('hash'),
                        'upload_method': 'program_upload',
                        'extracted_from_zip': True
                    }
                }
                for file_info in ladder_zip_extract_result['extracted_ladder_files']
            ]
            
            pgm_ladder_csv_documents = self.document_service.bulk_create_ladder_csv_documents(
                pgm_ladder_csv_documents_data
            )
            
            logger.info(
                f"âœ… [Step 12] ë ˆë” CSV ë¬¸ì„œ ë ˆì½”ë“œ ìƒì„± ì™„ë£Œ: "
                f"{len(pgm_ladder_csv_documents)}ê°œ"
            )
            
            # 13. í…œí”Œë¦¿ ë¬¸ì„œ ë ˆì½”ë“œ ìƒì„± (ìë™ìœ¼ë¡œ í…œí”Œë¦¿ íŒŒì‹±ë¨)
            pgm_template_document = self.document_service.create_template_document(
                document_name=template_save_result['filename'],
                original_filename=template_save_result['filename'],
                file_key=f"{pgm_id}/{self.settings.pgm_template_dir_name}/{template_save_result['filename']}",
                upload_path=str(template_save_result['file_path']),
                file_size=template_save_result['size'],
                pgm_id=pgm_id,
                user_id=create_user,
                is_public=False,
                metadata={
                    'file_hash': template_save_result.get('hash'),
                    'upload_method': 'program_upload'
                }
            )
            # â†‘ create_template_document() ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ:
            #    - ProgramTemplateProcessor í˜¸ì¶œ
            #    - í…œí”Œë¦¿ íŒŒì‹±
            #    - PGM_TEMPLATE í…Œì´ë¸” INSERT
            
            logger.info(
                f"âœ… [Step 13] í…œí”Œë¦¿ ë¬¸ì„œ ë ˆì½”ë“œ ìƒì„± ë° íŒŒì‹± ì™„ë£Œ: "
                f"{pgm_template_document.document_id}"
            )
            
            # 14. í”„ë¡œê·¸ë¨ ë ˆì½”ë“œ ìƒì„±
            program = self.program_service.create_program(
                pgm_id=pgm_id,
                pgm_name=pgm_name,
                pgm_version=pgm_version,
                description=description,
                create_user=create_user,
                notes=notes
            )
            
            logger.info(
                f"âœ… [Step 14] í”„ë¡œê·¸ë¨ ë ˆì½”ë“œ ìƒì„± ì™„ë£Œ: {pgm_id}"
            )
            
            # 15. ì»¤ë°‹
            self.db.commit()
            logger.info(f"ğŸ‰ [Success] í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì™„ë£Œ: {pgm_id}")
            
            # 16. ê²°ê³¼ ë°˜í™˜
            return {
                'program': program,
                'pgm_id': pgm_id,
                'validation_result': validation_result,
                'saved_files': {
                    'ladder_csv_documents': [
                        {
                            'document_id': doc.document_id,
                            'document_name': doc.document_name,
                            'upload_path': doc.upload_path
                        }
                        for doc in pgm_ladder_csv_documents
                    ],
                    'template_document': {
                        'document_id': pgm_template_document.document_id,
                        'document_name': pgm_template_document.document_name,
                        'upload_path': pgm_template_document.upload_path
                    }
                },
                'summary': {
                    'total_ladder_files': len(pgm_ladder_csv_documents),
                    'template_parsed': True,
                    'template_row_count': len(template_structure['logic_ids'])
                },
                'message': 'í”„ë¡œê·¸ë¨ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤'
            }
            
        except HandledException:
            # HandledExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
            self.db.rollback()
            
            # ì €ì¥ëœ íŒŒì¼ ì‚­ì œ
            if saved_file_paths:
                self.file_storage_service.delete_files(saved_file_paths)
                logger.info(f"ğŸ”„ [Rollback] ì €ì¥ëœ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            
            raise
            
        except Exception as e:
            # ë¡¤ë°±
            self.db.rollback()
            logger.error(f"âŒ [Error] í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            
            # ì €ì¥ëœ íŒŒì¼ ì‚­ì œ
            if saved_file_paths:
                try:
                    self.file_storage_service.delete_files(saved_file_paths)
                    logger.info(f"ğŸ”„ [Rollback] ì €ì¥ëœ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                except Exception as cleanup_error:
                    logger.error(f"âŒ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(cleanup_error)}")
            
            raise HandledException(
                ResponseCode.UNDEFINED_ERROR,
                msg=f"í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                e=e
            )
    
    def _filter_ladder_zip(
        self,
        pgm_ladder_zip_file: UploadFile,
        keep_files: List[str]
    ) -> bytes:
        """
        ë ˆë” ZIPì—ì„œ í•„ìš”í•œ íŒŒì¼ë§Œ ë‚¨ê¸°ê³  ìƒˆë¡œìš´ ZIP ìƒì„±
        
        Args:
            pgm_ladder_zip_file: ì›ë³¸ ë ˆë” ZIP íŒŒì¼
            keep_files: ìœ ì§€í•  íŒŒì¼ ëª©ë¡ (ì˜ˆ: ["0000_11.csv", "0001_11.csv"])
            
        Returns:
            bytes: í•„í„°ë§ëœ ZIP íŒŒì¼ ë°”ì´íŠ¸
        """
        try:
            # ì›ë³¸ ZIP ì½ê¸°
            original_content = pgm_ladder_zip_file.file.read()
            pgm_ladder_zip_file.file.seek(0)  # í¬ì¸í„° ë³µì›
            
            # ìƒˆë¡œìš´ ZIP ìƒì„±
            filtered_buffer = io.BytesIO()
            
            with zipfile.ZipFile(io.BytesIO(original_content), 'r') as original_zip:
                with zipfile.ZipFile(filtered_buffer, 'w', zipfile.ZIP_DEFLATED) as new_zip:
                    for info in original_zip.infolist():
                        if not info.is_dir():
                            filename = Path(info.filename).name
                            if filename in keep_files:
                                # í•„ìš”í•œ íŒŒì¼ë§Œ ë³µì‚¬
                                new_zip.writestr(info, original_zip.read(info.filename))
            
            filtered_buffer.seek(0)
            filtered_bytes = filtered_buffer.read()
            
            logger.info(
                f"ë ˆë” ZIP í•„í„°ë§ ì™„ë£Œ: "
                f"{len(keep_files)}ê°œ íŒŒì¼ ìœ ì§€"
            )
            
            return filtered_bytes
            
        except Exception as e:
            logger.error(f"âŒ ZIP íŒŒì¼ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            raise HandledException(
                ResponseCode.DOCUMENT_UPLOAD_ERROR,
                msg=f"ZIP íŒŒì¼ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}",
                e=e
            )
