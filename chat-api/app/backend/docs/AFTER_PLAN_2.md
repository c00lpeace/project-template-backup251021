# ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ - ìƒì„¸ ì„¤ëª…

## ğŸ“‹ ëª©ì°¨

1. [Phase 6: ì„±ëŠ¥ ìµœì í™”](#phase-6-ì„±ëŠ¥-ìµœì í™”)
2. [í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±](#í†µí•©-í…ŒìŠ¤íŠ¸-ì‘ì„±)
3. [API ë¬¸ì„œ ë³´ê°•](#api-ë¬¸ì„œ-ë³´ê°•)
4. [ì¶”ê°€ ê°œì„  ì œì•ˆ](#ì¶”ê°€-ê°œì„ -ì œì•ˆ)
5. [ìš°ì„ ìˆœìœ„ ë° ë¡œë“œë§µ](#ìš°ì„ ìˆœìœ„-ë°-ë¡œë“œë§µ)

---

## Phase 6: ì„±ëŠ¥ ìµœì í™”

### ğŸ¯ ëª©í‘œ
í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì „ì²´ ì›Œí¬í”Œë¡œìš°ì˜ ì²˜ë¦¬ ì‹œê°„ì„ 25-40% ë‹¨ì¶•

### ğŸ“Š í˜„ì¬ ì„±ëŠ¥ ë¶„ì„

**í˜„ì¬ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ (100ê°œ ë ˆë” íŒŒì¼ ê¸°ì¤€):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: ê²€ì¦                    â†’ 500ms    â”‚
â”‚  â”œâ”€ íŒŒì¼ íƒ€ì…/í¬ê¸° ê²€ì¦          100ms      â”‚
â”‚  â”œâ”€ í…œí”Œë¦¿ êµ¬ì¡° ê²€ì¦             200ms      â”‚
â”‚  â”œâ”€ ZIP êµ¬ì¡° ê²€ì¦                100ms      â”‚
â”‚  â””â”€ ë ˆë” íŒŒì¼ ë§¤ì¹­ ê²€ì¦          100ms      â”‚
â”‚                                              â”‚
â”‚ Phase 2: íŒŒì¼ ì €ì¥               â†’ 2000ms   â”‚
â”‚  â”œâ”€ ZIP ì••ì¶• í•´ì œ                1500ms     â”‚
â”‚  â””â”€ í…œí”Œë¦¿ íŒŒì¼ ì €ì¥             500ms      â”‚
â”‚                                              â”‚
â”‚ Phase 3: DB ì €ì¥                 â†’ 1500ms   â”‚
â”‚  â”œâ”€ ë ˆë” CSV ë¬¸ì„œ ì¼ê´„ ìƒì„±      500ms      â”‚
â”‚  â”œâ”€ í…œí”Œë¦¿ ë¬¸ì„œ ìƒì„± + íŒŒì‹±      800ms      â”‚
â”‚  â””â”€ í”„ë¡œê·¸ë¨ ë ˆì½”ë“œ ìƒì„±         200ms      â”‚
â”‚                                              â”‚
â”‚ ì „ì²´ ì‹œê°„:                       4000ms      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ ìµœì í™” í•­ëª©

#### 1. Bulk INSERT ìµœì í™” (Phase 3 DB ì €ì¥)

**í˜„ì¬ ë¬¸ì œ:**
```python
# ai_backend/api/services/document_service.py
def bulk_create_ladder_csv_documents(self, documents_data: List[Dict]) -> List[Document]:
    documents = []
    for data in documents_data:
        # ê°œë³„ INSERT (Në²ˆ í˜¸ì¶œ)
        document = self.document_crud.create_document(...)
        documents.append(document)
    return documents
```

**ë¬¸ì œì :**
- 100ê°œ íŒŒì¼ â†’ 100ë²ˆ INSERT ì‹¤í–‰
- ê° INSERTë§ˆë‹¤ DB ì™•ë³µ (Network I/O)
- íŠ¸ëœì­ì…˜ ì˜¤ë²„í—¤ë“œ

**ìµœì í™” ë°©ì•ˆ:**
```python
# SQLAlchemy bulk_insert_mappings ì‚¬ìš©
def bulk_create_ladder_csv_documents(self, documents_data: List[Dict]) -> List[Document]:
    """
    ì„±ëŠ¥ ìµœì í™”: bulk_insert_mappings ì‚¬ìš©
    - 100ê°œ INSERT â†’ 1ë²ˆ Batch INSERT
    - ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 500ms â†’ 100ms (80% ê°œì„ )
    """
    # 1. Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ë©”ëª¨ë¦¬)
    document_dicts = []
    for data in documents_data:
        document_dict = {
            'document_id': generate_id(),
            'document_name': data['document_name'],
            'user_id': data['user_id'],
            ...
        }
        document_dicts.append(document_dict)
    
    # 2. Bulk INSERT (1ë²ˆ ì‹¤í–‰)
    self.db.bulk_insert_mappings(Document, document_dicts)
    
    # 3. ìƒì„±ëœ ë ˆì½”ë“œ ì¡°íšŒ (1ë²ˆ SELECT)
    document_ids = [d['document_id'] for d in document_dicts]
    documents = self.db.query(Document).filter(
        Document.document_id.in_(document_ids)
    ).all()
    
    return documents
```

**ì˜ˆìƒ íš¨ê³¼:**
- **ì²˜ë¦¬ ì‹œê°„:** 500ms â†’ 100ms (80% ê°œì„ )
- **DB ì™•ë³µ:** 100ë²ˆ â†’ 2ë²ˆ (98% ê°ì†Œ)
- **CPU ì‚¬ìš©ë¥ :** 30% ê°ì†Œ

---

#### 2. í…œí”Œë¦¿ íŒŒì‹± ìµœì í™” (Phase 3 DB ì €ì¥)

**í˜„ì¬ ë¬¸ì œ:**
```python
# ai_backend/api/services/template_service.py
def parse_and_save_template(self, document_id: str, pgm_id: str, file_path: str):
    # Excel íŒŒì¼ ì½ê¸° (ëŠë¦¼)
    df = pd.read_excel(file_path)  # 800ms
    
    # ê° í–‰ë§ˆë‹¤ INSERT (Në²ˆ)
    for _, row in df.iterrows():
        self.template_crud.create_template_row(
            pgm_id=pgm_id,
            folder_id=row['Folder ID'],
            logic_id=row['Logic ID'],
            ...
        )
```

**ë¬¸ì œì :**
- pandas read_excelì´ ëŠë¦¼ (800ms)
- ë°˜ë³µë¬¸ ë‚´ë¶€ì—ì„œ INSERT (Në²ˆ)
- í…œí”Œë¦¿ í–‰ì´ ë§ì„ìˆ˜ë¡ ì‹œê°„ ì¦ê°€ (ì„ í˜•)

**ìµœì í™” ë°©ì•ˆ:**

**ë°©ì•ˆ 1: openpyxl ì§ì ‘ ì‚¬ìš©**
```python
# pandas ëŒ€ì‹  openpyxl ì§ì ‘ ì‚¬ìš©
from openpyxl import load_workbook

def parse_template_optimized(self, file_path: str) -> List[Dict]:
    """
    ì„±ëŠ¥ ìµœì í™”: openpyxl ì§ì ‘ ì‚¬ìš©
    - pandas ì˜¤ë²„í—¤ë“œ ì œê±°
    - ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 800ms â†’ 300ms (62% ê°œì„ )
    """
    wb = load_workbook(file_path, read_only=True)  # ì½ê¸° ì „ìš© ëª¨ë“œ
    ws = wb.active
    
    # í—¤ë” ì¶”ì¶œ
    headers = [cell.value for cell in ws[1]]
    
    # ë°ì´í„° ì¶”ì¶œ (ì œë„¤ë ˆì´í„°)
    rows = []
    for row in ws.iter_rows(min_row=2, values_only=True):
        row_dict = dict(zip(headers, row))
        rows.append(row_dict)
    
    return rows
```

**ë°©ì•ˆ 2: Bulk INSERT ì ìš©**
```python
def save_template_data_optimized(
    self, 
    pgm_id: str, 
    template_data: List[Dict]
):
    """
    ì„±ëŠ¥ ìµœì í™”: bulk_insert_mappings ì‚¬ìš©
    - Në²ˆ INSERT â†’ 1ë²ˆ Batch INSERT
    """
    template_dicts = [
        {
            'pgm_id': pgm_id,
            'folder_id': row['Folder ID'],
            'logic_id': row['Logic ID'],
            ...
        }
        for row in template_data
    ]
    
    self.db.bulk_insert_mappings(PgmTemplate, template_dicts)
```

**ì˜ˆìƒ íš¨ê³¼:**
- **ì²˜ë¦¬ ì‹œê°„:** 800ms â†’ 300ms (62% ê°œì„ )
- **ë©”ëª¨ë¦¬ ì‚¬ìš©:** 40% ê°ì†Œ (read_only ëª¨ë“œ)
- **í™•ì¥ì„±:** 1000í–‰ í…œí”Œë¦¿ë„ 1ì´ˆ ì´ë‚´ ì²˜ë¦¬

---

#### 3. íŒŒì¼ I/O ìµœì í™” (Phase 2 íŒŒì¼ ì €ì¥)

**í˜„ì¬ ë¬¸ì œ:**
```python
# ai_backend/api/services/file_storage_service.py
def save_and_extract_ladder_zip(self, ladder_zip_bytes: bytes, pgm_id: str):
    # ZIP ì••ì¶• í•´ì œ (ë™ê¸° ë°©ì‹)
    with zipfile.ZipFile(io.BytesIO(ladder_zip_bytes), 'r') as zip_ref:
        for file_info in zip_ref.infolist():
            # ê° íŒŒì¼ë§ˆë‹¤ ë™ê¸° I/O
            content = zip_ref.read(file_info.filename)
            file_path = ladder_dir / file_info.filename
            file_path.write_bytes(content)  # ë™ê¸° ì“°ê¸°
```

**ë¬¸ì œì :**
- ë™ê¸° I/O â†’ íŒŒì¼ 100ê°œ ì €ì¥ ì‹œ 1.5ì´ˆ
- CPU ëŒ€ê¸° ì‹œê°„ ì¦ê°€
- ë³‘ë ¬ ì²˜ë¦¬ ë¶ˆê°€

**ìµœì í™” ë°©ì•ˆ:**

**ë°©ì•ˆ 1: ë²„í¼ í¬ê¸° ì¡°ì •**
```python
# ë²„í¼ í¬ê¸°ë¥¼ ëŠ˜ë ¤ì„œ I/O íšŸìˆ˜ ê°ì†Œ
BUFFER_SIZE = 1024 * 1024  # 1MB (ê¸°ë³¸ 64KB â†’ 1MB)

def save_file_with_buffer(self, content: bytes, file_path: Path):
    """
    ì„±ëŠ¥ ìµœì í™”: ë²„í¼ í¬ê¸° ì¡°ì •
    - ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 1500ms â†’ 1200ms (20% ê°œì„ )
    """
    with open(file_path, 'wb', buffering=BUFFER_SIZE) as f:
        f.write(content)
```

**ë°©ì•ˆ 2: ë¹„ë™ê¸° I/O (ì„ íƒì‚¬í•­)**
```python
import asyncio
import aiofiles

async def save_files_async(self, files_data: List[Dict]):
    """
    ì„±ëŠ¥ ìµœì í™”: ë¹„ë™ê¸° íŒŒì¼ ì €ì¥
    - ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 1500ms â†’ 800ms (47% ê°œì„ )
    - ì£¼ì˜: FastAPI ë¹„ë™ê¸° ì—”ë“œí¬ì¸íŠ¸ í•„ìš”
    """
    tasks = []
    for file_data in files_data:
        task = self._save_file_async(
            file_data['content'], 
            file_data['path']
        )
        tasks.append(task)
    
    await asyncio.gather(*tasks)

async def _save_file_async(self, content: bytes, file_path: Path):
    async with aiofiles.open(file_path, 'wb') as f:
        await f.write(content)
```

**ì˜ˆìƒ íš¨ê³¼:**
- **ë²„í¼ ìµœì í™”:** 1500ms â†’ 1200ms (20% ê°œì„ )
- **ë¹„ë™ê¸° I/O:** 1500ms â†’ 800ms (47% ê°œì„ )
- **CPU ì‚¬ìš©ë¥ :** 25% ê°ì†Œ

---

#### 4. ë©”ëª¨ë¦¬ ìµœì í™”

**í˜„ì¬ ë¬¸ì œ:**
```python
# ì „ì²´ ZIPì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
original_content = pgm_ladder_zip_file.file.read()  # 100MB ë©”ëª¨ë¦¬ ì‚¬ìš©
```

**ìµœì í™” ë°©ì•ˆ:**
```python
# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
def extract_zip_streaming(self, zip_file: UploadFile, extract_dir: Path):
    """
    ë©”ëª¨ë¦¬ ìµœì í™”: ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹
    - ë©”ëª¨ë¦¬ ì‚¬ìš©: 100MB â†’ 10MB (90% ê°ì†Œ)
    """
    with zipfile.ZipFile(zip_file.file, 'r') as zip_ref:
        for file_info in zip_ref.infolist():
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°/ì“°ê¸°
            with zip_ref.open(file_info.filename) as source:
                target_path = extract_dir / file_info.filename
                with open(target_path, 'wb') as target:
                    while True:
                        chunk = source.read(8192)  # 8KB ì²­í¬
                        if not chunk:
                            break
                        target.write(chunk)
```

**ì˜ˆìƒ íš¨ê³¼:**
- **ë©”ëª¨ë¦¬ ì‚¬ìš©:** 100MB â†’ 10MB (90% ê°ì†Œ)
- **ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥:** 500MB ZIPë„ ì²˜ë¦¬ ê°€ëŠ¥

---

### ğŸ“ˆ ìµœì í™” í›„ ì˜ˆìƒ ì„±ëŠ¥

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: ê²€ì¦                    â†’ 500ms    â”‚ (ë³€í™” ì—†ìŒ)
â”‚                                              â”‚
â”‚ Phase 2: íŒŒì¼ ì €ì¥               â†’ 1200ms   â”‚ â¬‡ï¸ 800ms ê°ì†Œ (40%)
â”‚  â”œâ”€ ZIP ì••ì¶• í•´ì œ (ë²„í¼ ìµœì í™”)  700ms      â”‚
â”‚  â””â”€ í…œí”Œë¦¿ íŒŒì¼ ì €ì¥             500ms      â”‚
â”‚                                              â”‚
â”‚ Phase 3: DB ì €ì¥                 â†’ 600ms    â”‚ â¬‡ï¸ 900ms ê°ì†Œ (60%)
â”‚  â”œâ”€ ë ˆë” CSV ì¼ê´„ ìƒì„± (Bulk)    100ms      â”‚
â”‚  â”œâ”€ í…œí”Œë¦¿ íŒŒì‹± + ì €ì¥ (ìµœì í™”)  300ms      â”‚
â”‚  â””â”€ í”„ë¡œê·¸ë¨ ë ˆì½”ë“œ ìƒì„±         200ms      â”‚
â”‚                                              â”‚
â”‚ ì „ì²´ ì‹œê°„:                       2300ms      â”‚ â¬‡ï¸ 1700ms ê°ì†Œ (42%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ê°œì„  íš¨ê³¼:**
- **ì „ì²´ ì²˜ë¦¬ ì‹œê°„:** 4000ms â†’ 2300ms (42% ê°œì„ )
- **DB ì²˜ë¦¬ ì‹œê°„:** 1500ms â†’ 600ms (60% ê°œì„ )
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:** 90% ê°ì†Œ
- **í™•ì¥ì„±:** ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥

---

### ğŸ› ï¸ ì‘ì—… ìˆœì„œ

#### Step 1: Bulk INSERT ìµœì í™” (ìš°ì„ ìˆœìœ„ 1)
```
1. DocumentService.bulk_create_ladder_csv_documents() ìˆ˜ì •
2. TemplateService.save_template_data() ìˆ˜ì •
3. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
4. ë²¤ì¹˜ë§ˆí¬ ì¸¡ì • (Before/After)

ì˜ˆìƒ ì‹œê°„: 2ì‹œê°„
```

#### Step 2: í…œí”Œë¦¿ íŒŒì‹± ìµœì í™” (ìš°ì„ ìˆœìœ„ 2)
```
1. openpyxl ì§ì ‘ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
2. read_only ëª¨ë“œ ì ìš©
3. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
4. ë²¤ì¹˜ë§ˆí¬ ì¸¡ì •

ì˜ˆìƒ ì‹œê°„: 1.5ì‹œê°„
```

#### Step 3: íŒŒì¼ I/O ìµœì í™” (ìš°ì„ ìˆœìœ„ 3)
```
1. ë²„í¼ í¬ê¸° ì¡°ì •
2. (ì„ íƒ) ë¹„ë™ê¸° I/O ì ìš©
3. ë©”ëª¨ë¦¬ ìµœì í™” (ìŠ¤íŠ¸ë¦¬ë°)
4. í†µí•© í…ŒìŠ¤íŠ¸

ì˜ˆìƒ ì‹œê°„: 2ì‹œê°„
```

#### Step 4: ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (í•„ìˆ˜)
```
1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ (10, 50, 100, 500ê°œ íŒŒì¼)
2. locust ë˜ëŠ” pytest-benchmarkë¡œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
3. ê²°ê³¼ ë¶„ì„ ë° ë¬¸ì„œí™”
4. ë³‘ëª© ì§€ì  ì¶”ê°€ í™•ì¸

ì˜ˆìƒ ì‹œê°„: 1.5ì‹œê°„
```

**ì´ ì˜ˆìƒ ì‹œê°„:** 7ì‹œê°„

---

## í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±

### ğŸ¯ ëª©í‘œ
í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì›Œí¬í”Œë¡œìš°ì˜ ì•ˆì •ì„±ì„ 80% â†’ 95%ë¡œ í–¥ìƒ

### ğŸ“‹ í…ŒìŠ¤íŠ¸ ë²”ìœ„

#### 1. ì •ìƒ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

**test_upload_program_success.py**
```python
"""
í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
1. ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ (10ê°œ ë ˆë” íŒŒì¼)
2. ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ (100ê°œ ë ˆë” íŒŒì¼)
3. ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ (ëŒ€ìš©ëŸ‰ ZIP 50MB)
4. ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ (íŠ¹ìˆ˜ë¬¸ì í¬í•¨ íŒŒì¼ëª…)
5. ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ (í•œê¸€ íŒŒì¼ëª…)

ê²€ì¦ í•­ëª©:
- PGM_ID ìë™ ìƒì„± í™•ì¸
- íŒŒì¼ ì €ì¥ ê²½ë¡œ í™•ì¸
- DOCUMENTS ë ˆì½”ë“œ ìƒì„± í™•ì¸
- PGM_TEMPLATE ë ˆì½”ë“œ ìƒì„± í™•ì¸
- PROGRAMS ë ˆì½”ë“œ ìƒì„± í™•ì¸
- ì‘ë‹µ ì‹œê°„ (4ì´ˆ ì´ë‚´)
"""

def test_upload_program_with_10_files(client, test_files):
    """10ê°œ ë ˆë” íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    # Given: 10ê°œ ë ˆë” íŒŒì¼ + í…œí”Œë¦¿
    ladder_zip = create_test_zip(10)
    template_xlsx = create_test_template(10)
    
    # When: ì—…ë¡œë“œ API í˜¸ì¶œ
    response = client.post(
        "/programs/upload",
        files={
            "pgm_ladder_zip_file": ladder_zip,
            "pgm_template_file": template_xlsx
        },
        data={
            "pgm_name": "Test Program",
            "create_user": "test_user"
        }
    )
    
    # Then: ê²€ì¦
    assert response.status_code == 201
    data = response.json()
    
    # PGM_ID í™•ì¸
    assert data['pgm_id'].startswith('PGM_')
    
    # íŒŒì¼ ì €ì¥ í™•ì¸
    assert len(data['saved_files']['ladder_csv_documents']) == 10
    assert data['saved_files']['template_document'] is not None
    
    # DB ë ˆì½”ë“œ í™•ì¸
    pgm = db.query(Programs).filter_by(pgm_id=data['pgm_id']).first()
    assert pgm is not None
    assert pgm.pgm_name == "Test Program"
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    for doc in data['saved_files']['ladder_csv_documents']:
        file_path = Path(doc['upload_path'])
        assert file_path.exists()

def test_upload_program_with_100_files(client, test_files):
    """100ê°œ ë ˆë” íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì„±ëŠ¥ í™•ì¸)"""
    import time
    
    ladder_zip = create_test_zip(100)
    template_xlsx = create_test_template(100)
    
    start_time = time.time()
    response = client.post("/programs/upload", ...)
    elapsed_time = time.time() - start_time
    
    # ì„±ëŠ¥ í™•ì¸ (4ì´ˆ ì´ë‚´)
    assert elapsed_time < 4.0
    assert response.status_code == 201
    
    # íŒŒì¼ ê°œìˆ˜ í™•ì¸
    data = response.json()
    assert len(data['saved_files']['ladder_csv_documents']) == 100

def test_upload_program_with_large_zip(client):
    """ëŒ€ìš©ëŸ‰ ZIP (50MB) ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    ladder_zip = create_large_test_zip(50 * 1024 * 1024)  # 50MB
    template_xlsx = create_test_template(10)
    
    response = client.post("/programs/upload", ...)
    
    assert response.status_code == 201
```

---

#### 2. ê²€ì¦ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

**test_upload_program_validation_errors.py**
```python
"""
ê²€ì¦ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
1. íŒŒì¼ íƒ€ì… ì˜¤ë¥˜ (ZIP ëŒ€ì‹  PDF)
2. íŒŒì¼ í¬ê¸° ì´ˆê³¼ (101MB)
3. í…œí”Œë¦¿ êµ¬ì¡° ì˜¤ë¥˜ (í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½)
4. ë ˆë” íŒŒì¼ ëˆ„ë½ (í…œí”Œë¦¿ì— ìˆì§€ë§Œ ZIPì— ì—†ìŒ)
5. ZIP ì†ìƒ (ì••ì¶• í•´ì œ ì‹¤íŒ¨)
6. í…œí”Œë¦¿ ì†ìƒ (ì½ê¸° ì‹¤íŒ¨)

ê²€ì¦ í•­ëª©:
- ì ì ˆí•œ ì—ëŸ¬ ì½”ë“œ ë°˜í™˜
- ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
- íŒŒì¼ ì €ì¥ ì•ˆ ë¨ í™•ì¸
- DB ë ˆì½”ë“œ ìƒì„± ì•ˆ ë¨ í™•ì¸
- ë¡¤ë°± í™•ì¸ (íŒŒì¼ ì‚­ì œ)
"""

def test_invalid_file_type(client):
    """ì˜ëª»ëœ íŒŒì¼ íƒ€ì… ì—…ë¡œë“œ"""
    # Given: ZIP ëŒ€ì‹  PDF
    invalid_file = create_pdf_file()
    template_xlsx = create_test_template(10)
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post(
        "/programs/upload",
        files={
            "pgm_ladder_zip_file": invalid_file,
            "pgm_template_file": template_xlsx
        },
        data={"pgm_name": "Test", "create_user": "test"}
    )
    
    # Then: ê²€ì¦
    assert response.status_code == 400
    data = response.json()
    assert "ZIP" in data['message']
    assert "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹" in data['message']
    
    # íŒŒì¼ ì €ì¥ ì•ˆ ë¨ í™•ì¸
    assert not Path(f"uploads/PGM_*").exists()

def test_file_size_exceeded(client):
    """íŒŒì¼ í¬ê¸° ì´ˆê³¼"""
    # Given: 101MB ZIP (í™˜ê²½ë³€ìˆ˜: pgm_ladder_zip_max_size=100MB)
    large_zip = create_large_test_zip(101 * 1024 * 1024)
    template_xlsx = create_test_template(10)
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ê²€ì¦
    assert response.status_code == 400
    assert "í¬ê¸°" in response.json()['message']
    assert "100MB" in response.json()['message']

def test_missing_required_columns_in_template(client):
    """í…œí”Œë¦¿ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½"""
    # Given: Logic ID ì»¬ëŸ¼ì´ ì—†ëŠ” í…œí”Œë¦¿
    ladder_zip = create_test_zip(10)
    invalid_template = create_template_without_logic_id()
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ê²€ì¦
    assert response.status_code == 400
    assert "Logic ID" in response.json()['message']
    assert "í•„ìˆ˜ ì»¬ëŸ¼" in response.json()['message']

def test_missing_ladder_files(client):
    """ë ˆë” íŒŒì¼ ëˆ„ë½"""
    # Given: í…œí”Œë¦¿ì—ëŠ” 10ê°œ, ZIPì—ëŠ” 5ê°œë§Œ
    ladder_zip = create_test_zip(5)  # 5ê°œë§Œ
    template_xlsx = create_test_template(10)  # 10ê°œ í•„ìš”
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ê²€ì¦
    assert response.status_code == 400
    data = response.json()
    assert "ëˆ„ë½" in data['message']
    assert len(data['validation_result']['missing_files']) == 5

def test_corrupted_zip_file(client):
    """ì†ìƒëœ ZIP íŒŒì¼"""
    # Given: ì†ìƒëœ ZIP
    corrupted_zip = create_corrupted_zip()
    template_xlsx = create_test_template(10)
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ê²€ì¦
    assert response.status_code == 400
    assert "ì†ìƒ" in response.json()['message']
```

---

#### 3. íŠ¸ëœì­ì…˜ ë¡¤ë°± í…ŒìŠ¤íŠ¸

**test_upload_program_rollback.py**
```python
"""
íŠ¸ëœì­ì…˜ ë¡¤ë°± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
1. íŒŒì¼ ì €ì¥ í›„ DB INSERT ì‹¤íŒ¨
2. ë ˆë” CSV ì €ì¥ í›„ í…œí”Œë¦¿ íŒŒì‹± ì‹¤íŒ¨
3. í…œí”Œë¦¿ ì €ì¥ í›„ í”„ë¡œê·¸ë¨ ìƒì„± ì‹¤íŒ¨
4. ì¤‘ê°„ì— DB ì—°ê²° ëŠê¹€
5. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

ê²€ì¦ í•­ëª©:
- DB ë¡¤ë°± í™•ì¸ (ë ˆì½”ë“œ ì—†ìŒ)
- ì €ì¥ëœ íŒŒì¼ ì‚­ì œ í™•ì¸
- ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
- ë¡œê·¸ ê¸°ë¡ í™•ì¸
"""

def test_rollback_on_db_error(client, db_session, monkeypatch):
    """DB ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±"""
    # Given: ì •ìƒ íŒŒì¼
    ladder_zip = create_test_zip(10)
    template_xlsx = create_test_template(10)
    
    # í”„ë¡œê·¸ë¨ ìƒì„± ì‹œ ì—ëŸ¬ ë°œìƒí•˜ë„ë¡ ì„¤ì •
    def mock_create_program(*args, **kwargs):
        raise Exception("DB Connection Error")
    
    monkeypatch.setattr(
        "ai_backend.api.services.program_service.ProgramService.create_program",
        mock_create_program
    )
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ê²€ì¦
    assert response.status_code == 500
    
    # DB ë ˆì½”ë“œ ì—†ìŒ í™•ì¸
    assert db_session.query(Programs).count() == 0
    assert db_session.query(Document).count() == 0
    assert db_session.query(PgmTemplate).count() == 0
    
    # ì €ì¥ëœ íŒŒì¼ ì—†ìŒ í™•ì¸
    assert not Path("uploads/PGM_*").exists()

def test_rollback_on_template_parsing_error(client, monkeypatch):
    """í…œí”Œë¦¿ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¡¤ë°±"""
    ladder_zip = create_test_zip(10)
    template_xlsx = create_test_template(10)
    
    # í…œí”Œë¦¿ íŒŒì‹± ì‹œ ì—ëŸ¬ ë°œìƒ
    def mock_parse_template(*args, **kwargs):
        raise Exception("Excel Parse Error")
    
    monkeypatch.setattr(
        "ai_backend.api.services.template_service.TemplateService.parse_template_xlsx",
        mock_parse_template
    )
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ë¡¤ë°± í™•ì¸
    assert response.status_code == 500
    assert not Path("uploads/PGM_*").exists()

def test_rollback_on_disk_full(client, monkeypatch):
    """ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ì‹œ ë¡¤ë°±"""
    ladder_zip = create_test_zip(10)
    template_xlsx = create_test_template(10)
    
    # íŒŒì¼ ì €ì¥ ì‹œ ë””ìŠ¤í¬ ë¶€ì¡± ì—ëŸ¬
    def mock_save_file(*args, **kwargs):
        raise OSError("[Errno 28] No space left on device")
    
    monkeypatch.setattr(
        "ai_backend.api.services.file_storage_service.FileStorageService.save_and_extract_ladder_zip",
        mock_save_file
    )
    
    # When: ì—…ë¡œë“œ ì‹œë„
    response = client.post("/programs/upload", ...)
    
    # Then: ì—ëŸ¬ í™•ì¸
    assert response.status_code == 500
    assert "ë””ìŠ¤í¬" in response.json()['message'] or "ê³µê°„" in response.json()['message']
```

---

#### 4. ë™ì‹œì„± í…ŒìŠ¤íŠ¸

**test_upload_program_concurrency.py**
```python
"""
ë™ì‹œì„± í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
1. ë™ì‹œ ì—…ë¡œë“œ 5ê°œ (ìˆœì°¨ ì‹¤í–‰)
2. ë™ì‹œ ì—…ë¡œë“œ 5ê°œ (ë³‘ë ¬ ì‹¤í–‰)
3. ê°™ì€ pgm_nameìœ¼ë¡œ ë™ì‹œ ì—…ë¡œë“œ (ì¶©ëŒ ë°©ì§€)
4. PGM_ID ìë™ ìƒì„± ê²½í•© ì¡°ê±´ (Race Condition)

ê²€ì¦ í•­ëª©:
- ëª¨ë“  ì—…ë¡œë“œ ì„±ê³µ
- PGM_ID ì¤‘ë³µ ì—†ìŒ
- íŒŒì¼ ê²½ë¡œ ì¶©ëŒ ì—†ìŒ
- íŠ¸ëœì­ì…˜ ê²©ë¦¬ ìˆ˜ì¤€ í™•ì¸
"""

import concurrent.futures
import threading

def test_concurrent_uploads_sequential(client):
    """ìˆœì°¨ì  ë™ì‹œ ì—…ë¡œë“œ (ê¸°ì¤€ì„ )"""
    results = []
    
    for i in range(5):
        ladder_zip = create_test_zip(10)
        template_xlsx = create_test_template(10)
        
        response = client.post(
            "/programs/upload",
            files={...},
            data={"pgm_name": f"Program {i}", "create_user": "test"}
        )
        
        results.append(response.json())
    
    # ëª¨ë“  ì—…ë¡œë“œ ì„±ê³µ í™•ì¸
    assert len(results) == 5
    for result in results:
        assert result['pgm_id'].startswith('PGM_')
    
    # PGM_ID ì¤‘ë³µ ì—†ìŒ í™•ì¸
    pgm_ids = [r['pgm_id'] for r in results]
    assert len(pgm_ids) == len(set(pgm_ids))

def test_concurrent_uploads_parallel(client):
    """ë³‘ë ¬ ë™ì‹œ ì—…ë¡œë“œ"""
    def upload_program(i):
        ladder_zip = create_test_zip(10)
        template_xlsx = create_test_template(10)
        
        response = client.post(
            "/programs/upload",
            files={...},
            data={"pgm_name": f"Program {i}", "create_user": "test"}
        )
        
        return response.json()
    
    # 5ê°œ ë³‘ë ¬ ì‹¤í–‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(upload_program, i) for i in range(5)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]
    
    # ê²€ì¦
    assert len(results) == 5
    
    # PGM_ID ì¤‘ë³µ ì—†ìŒ (Race Condition í…ŒìŠ¤íŠ¸)
    pgm_ids = [r['pgm_id'] for r in results]
    assert len(pgm_ids) == len(set(pgm_ids))
    
    # íŒŒì¼ ê²½ë¡œ ì¶©ëŒ ì—†ìŒ
    for result in results:
        pgm_id = result['pgm_id']
        upload_dir = Path(f"uploads/{pgm_id}")
        assert upload_dir.exists()

def test_same_name_concurrent_uploads(client):
    """ê°™ì€ ì´ë¦„ìœ¼ë¡œ ë™ì‹œ ì—…ë¡œë“œ (ì¶©ëŒ ë°©ì§€)"""
    def upload_program():
        ladder_zip = create_test_zip(10)
        template_xlsx = create_test_template(10)
        
        response = client.post(
            "/programs/upload",
            files={...},
            data={
                "pgm_name": "Same Name",  # ë™ì¼í•œ ì´ë¦„
                "create_user": "test"
            }
        )
        
        return response.json()
    
    # 5ê°œ ë³‘ë ¬ ì‹¤í–‰ (ëª¨ë‘ ê°™ì€ ì´ë¦„)
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(upload_program) for _ in range(5)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]
    
    # ëª¨ë‘ ì„±ê³µ (ì´ë¦„ì€ ê°™ì§€ë§Œ PGM_IDëŠ” ë‹¤ë¦„)
    assert len(results) == 5
    pgm_ids = [r['pgm_id'] for r in results]
    assert len(pgm_ids) == len(set(pgm_ids))

def test_pgm_id_generation_race_condition(client, db_session):
    """PGM_ID ìƒì„± ê²½í•© ì¡°ê±´ í…ŒìŠ¤íŠ¸"""
    # PROGRAM_SEQUENCE í…Œì´ë¸” ì§ì ‘ ì¡°ì‘
    # ë™ì‹œì— generate_pgm_id() í˜¸ì¶œ
    
    def generate_id():
        from ai_backend.api.services.sequence_service import SequenceService
        service = SequenceService(db_session)
        return service.generate_pgm_id()
    
    # 100ê°œ ë³‘ë ¬ ìƒì„±
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(generate_id) for _ in range(100)]
        pgm_ids = [f.result() for f in concurrent.futures.as_completed(futures)]
    
    # ì¤‘ë³µ ì—†ìŒ í™•ì¸
    assert len(pgm_ids) == 100
    assert len(set(pgm_ids)) == 100
    
    # ìˆœì°¨ ì¦ê°€ í™•ì¸
    pgm_numbers = [int(id.replace('PGM_', '')) for id in pgm_ids]
    assert max(pgm_numbers) - min(pgm_numbers) == 99
```

---

### ğŸ“Š í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ëª¨ë“ˆ                        í˜„ì¬    ëª©í‘œ    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ProgramUploadService       60%  â†’  95%       â”‚
â”‚ FileValidationService      70%  â†’  90%       â”‚
â”‚ FileStorageService         65%  â†’  90%       â”‚
â”‚ DocumentService            75%  â†’  85%       â”‚
â”‚ TemplateService            70%  â†’  85%       â”‚
â”‚ SequenceService            80%  â†’  95%       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì „ì²´ í‰ê·                   70%  â†’  90%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ› ï¸ í…ŒìŠ¤íŠ¸ ë„êµ¬

**pytest í”ŒëŸ¬ê·¸ì¸:**
```bash
pytest                    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
pytest-cov               # ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest-asyncio           # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
pytest-mock              # ëª¨í‚¹
pytest-benchmark         # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
pytest-xdist             # ë³‘ë ¬ ì‹¤í–‰
faker                    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
locust                   # ë¶€í•˜ í…ŒìŠ¤íŠ¸
```

**í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ:**
```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/test_program_upload_*.py -v

# ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest --cov=ai_backend.api.services --cov-report=html

# ë³‘ë ¬ ì‹¤í–‰ (8ê°œ ì›Œì»¤)
pytest -n 8 tests/integration/

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest tests/integration/test_upload_program_success.py::test_upload_program_with_100_files

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
pytest tests/benchmark/test_performance.py --benchmark-only
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„:** 8-10ì‹œê°„

---

## API ë¬¸ì„œ ë³´ê°•

### ğŸ¯ ëª©í‘œ
API ë¬¸ì„œ í’ˆì§ˆì„ í˜„ì¬ â†’ í”„ë¡œë•ì…˜ ìˆ˜ì¤€ìœ¼ë¡œ í–¥ìƒ

### ğŸ“‹ ë³´ê°• í•­ëª©

#### 1. Swagger ì˜ˆì œ ì¶”ê°€

**í˜„ì¬ ë¬¸ì œ:**
```python
# program_router.py
@router.post("/programs/upload")
async def upload_program_files(
    pgm_name: str = Form(..., description="í”„ë¡œê·¸ë¨ ëª…ì¹­"),
    ...
):
    """í”„ë¡œê·¸ë¨ íŒŒì¼ ì—…ë¡œë“œ"""
    # ì„¤ëª…ë§Œ ìˆê³  ì˜ˆì œ ì—†ìŒ
```

**ë³´ê°• ë°©ì•ˆ:**
```python
@router.post(
    "/programs/upload",
    response_model=ProgramUploadResponse,
    summary="í”„ë¡œê·¸ë¨ íŒŒì¼ ì—…ë¡œë“œ",
    description="""
    PLC í”„ë¡œê·¸ë¨ ë ˆë” íŒŒì¼(ZIP)ê³¼ í…œí”Œë¦¿ íŒŒì¼(XLSX)ì„ ì—…ë¡œë“œí•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    **ì£¼ìš” ê¸°ëŠ¥:**
    - PGM_ID ìë™ ìƒì„± (ì˜ˆ: PGM_1, PGM_2)
    - ë ˆë” íŒŒì¼ê³¼ í…œí”Œë¦¿ íŒŒì¼ ê²€ì¦
    - íŒŒì¼ ì €ì¥ ë° DB ë ˆì½”ë“œ ìƒì„±
    - íŠ¸ëœì­ì…˜ ë³´ì¥ (ì‹¤íŒ¨ ì‹œ ë¡¤ë°±)
    
    **ì²˜ë¦¬ ì‹œê°„:** 
    - 10ê°œ íŒŒì¼: ì•½ 1ì´ˆ
    - 100ê°œ íŒŒì¼: ì•½ 4ì´ˆ
    """,
    responses={
        201: {
            "description": "ì„±ê³µ",
            "content": {
                "application/json": {
                    "example": {
                        "pgm_id": "PGM_1",
                        "pgm_name": "Test Program",
                        "pgm_version": "1.0",
                        "description": "í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨",
                        "create_user": "admin",
                        "create_dt": "2025-11-06T10:30:00",
                        "validation_result": {
                            "validation_passed": True,
                            "matched_files": ["0000_11.csv", "0001_11.csv"],
                            "missing_files": [],
                            "unexpected_files": []
                        },
                        "saved_files": {
                            "ladder_csv_documents": [
                                {
                                    "document_id": "doc_20251106_103000_0000_11",
                                    "document_name": "0000_11.csv",
                                    "upload_path": "/uploads/PGM_1/ladder_files/0000_11.csv"
                                }
                            ],
                            "template_document": {
                                "document_id": "doc_20251106_103001_template",
                                "document_name": "template.xlsx",
                                "upload_path": "/uploads/PGM_1/template/template.xlsx"
                            }
                        },
                        "summary": {
                            "total_ladder_files": 2,
                            "template_parsed": True,
                            "template_row_count": 2
                        },
                        "message": "í”„ë¡œê·¸ë¨ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
                    }
                }
            }
        },
        400: {
            "description": "ê²€ì¦ ì‹¤íŒ¨",
            "content": {
                "application/json": {
                    "examples": {
                        "invalid_file_type": {
                            "summary": "ì˜ëª»ëœ íŒŒì¼ íƒ€ì…",
                            "value": {
                                "code": "DOCUMENT_INVALID_FILE_TYPE",
                                "message": "ë ˆë” ZIP íŒŒì¼ì€ .zip í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤",
                                "timestamp": "2025-11-06T10:30:00"
                            }
                        },
                        "file_size_exceeded": {
                            "summary": "íŒŒì¼ í¬ê¸° ì´ˆê³¼",
                            "value": {
                                "code": "DOCUMENT_FILE_TOO_LARGE",
                                "message": "íŒŒì¼ í¬ê¸°ê°€ 100.0MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
                                "timestamp": "2025-11-06T10:30:00"
                            }
                        },
                        "missing_files": {
                            "summary": "í•„ìˆ˜ íŒŒì¼ ëˆ„ë½",
                            "value": {
                                "code": "INVALID_DATA_FORMAT",
                                "message": "í•„ìˆ˜ ë ˆë” íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 0000_11.csv, 0001_11.csv",
                                "validation_result": {
                                    "validation_passed": False,
                                    "matched_files": [],
                                    "missing_files": ["0000_11.csv", "0001_11.csv"],
                                    "unexpected_files": []
                                },
                                "timestamp": "2025-11-06T10:30:00"
                            }
                        }
                    }
                }
            }
        },
        500: {
            "description": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜",
            "content": {
                "application/json": {
                    "example": {
                        "code": "UNDEFINED_ERROR",
                        "message": "í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: Database connection failed",
                        "timestamp": "2025-11-06T10:30:00"
                    }
                }
            }
        }
    }
)
async def upload_program_files(...):
    ...
```

---

#### 2. ì—ëŸ¬ ì½”ë“œ ë¬¸ì„œí™”

**errors.md ìƒì„±**
```markdown
# API ì—ëŸ¬ ì½”ë“œ ê°€ì´ë“œ

## í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ê´€ë ¨ ì—ëŸ¬

### DOCUMENT_INVALID_FILE_TYPE
**HTTP ìƒíƒœ:** 400  
**ì˜ë¯¸:** ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…  
**ë°œìƒ ì‹œì :** íŒŒì¼ íƒ€ì… ê²€ì¦ ë‹¨ê³„  
**í•´ê²° ë°©ë²•:** 
- ë ˆë” íŒŒì¼: `.zip` í˜•ì‹ ì‚¬ìš©
- í…œí”Œë¦¿ íŒŒì¼: `.xlsx` ë˜ëŠ” `.xls` í˜•ì‹ ì‚¬ìš©

**ì˜ˆì‹œ:**
```json
{
  "code": "DOCUMENT_INVALID_FILE_TYPE",
  "message": "ë ˆë” ZIP íŒŒì¼ì€ .zip í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤",
  "timestamp": "2025-11-06T10:30:00"
}
```

### DOCUMENT_FILE_TOO_LARGE
**HTTP ìƒíƒœ:** 400  
**ì˜ë¯¸:** íŒŒì¼ í¬ê¸° ì´ˆê³¼  
**ë°œìƒ ì‹œì :** íŒŒì¼ í¬ê¸° ê²€ì¦ ë‹¨ê³„  
**ìµœëŒ€ í¬ê¸°:**
- ë ˆë” ZIP: 100MB (í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê°€ëŠ¥)
- í…œí”Œë¦¿ íŒŒì¼: 10MB (í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê°€ëŠ¥)

**í•´ê²° ë°©ë²•:**
- íŒŒì¼ í¬ê¸° ì¤„ì´ê¸°
- ZIP ì••ì¶•ë¥  ì¡°ì •
- ë¶ˆí•„ìš”í•œ íŒŒì¼ ì œê±°

**ì˜ˆì‹œ:**
```json
{
  "code": "DOCUMENT_FILE_TOO_LARGE",
  "message": "íŒŒì¼ í¬ê¸°ê°€ 100.0MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤",
  "timestamp": "2025-11-06T10:30:00"
}
```

### INVALID_DATA_FORMAT
**HTTP ìƒíƒœ:** 400  
**ì˜ë¯¸:** ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜  
**ë°œìƒ ì‹œì :** ë ˆë” íŒŒì¼ ë§¤ì¹­ ê²€ì¦ ë‹¨ê³„  
**ì›ì¸:**
1. í…œí”Œë¦¿ì— ìˆëŠ” Logic IDê°€ ZIPì— ì—†ìŒ
2. í…œí”Œë¦¿ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½
3. í…œí”Œë¦¿ íŒŒì¼ ì†ìƒ

**í•´ê²° ë°©ë²•:**
1. í…œí”Œë¦¿ì˜ Logic IDì™€ ZIP íŒŒì¼ëª… ì¼ì¹˜ í™•ì¸
2. í…œí”Œë¦¿ì— í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸: Logic ID, Folder ID, Logic Name
3. í…œí”Œë¦¿ íŒŒì¼ ì¬ìƒì„±

**ì˜ˆì‹œ:**
```json
{
  "code": "INVALID_DATA_FORMAT",
  "message": "í•„ìˆ˜ ë ˆë” íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 0000_11.csv, 0001_11.csv",
  "validation_result": {
    "validation_passed": false,
    "matched_files": [],
    "missing_files": ["0000_11.csv", "0001_11.csv"],
    "unexpected_files": []
  },
  "timestamp": "2025-11-06T10:30:00"
}
```

### UNDEFINED_ERROR
**HTTP ìƒíƒœ:** 500  
**ì˜ë¯¸:** ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜  
**ë°œìƒ ì‹œì :** ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬  
**ì›ì¸:**
- DB ì—°ê²° ì‹¤íŒ¨
- ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜

**í•´ê²° ë°©ë²•:**
1. ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
2. ì ì‹œ í›„ ì¬ì‹œë„
3. ì§€ì† ì‹œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜

**ì˜ˆì‹œ:**
```json
{
  "code": "UNDEFINED_ERROR",
  "message": "í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: Database connection failed",
  "timestamp": "2025-11-06T10:30:00"
}
```
```

---

#### 3. ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±

**user_guide.md ìƒì„±**
```markdown
# PLC í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ ê°€ì´ë“œ

## ë¹ ë¥¸ ì‹œì‘

### 1. íŒŒì¼ ì¤€ë¹„

**í•„ìš”í•œ íŒŒì¼:**
1. **ë ˆë” CSV íŒŒì¼ë“¤ì´ ì••ì¶•ëœ ZIP** (pgm_ladder_zip_file)
   - í˜•ì‹: `.zip`
   - ìµœëŒ€ í¬ê¸°: 100MB
   - íŒŒì¼ëª… íŒ¨í„´: `XXXX_YY.csv` (ì˜ˆ: 0000_11.csv)

2. **í…œí”Œë¦¿ ì—‘ì…€ íŒŒì¼** (pgm_template_file)
   - í˜•ì‹: `.xlsx` ë˜ëŠ” `.xls`
   - ìµœëŒ€ í¬ê¸°: 10MB
   - í•„ìˆ˜ ì»¬ëŸ¼: Logic ID, Folder ID, Logic Name

**ZIP íŒŒì¼ êµ¬ì¡° ì˜ˆì‹œ:**
```
ladder_files.zip
â”œâ”€â”€ 0000_11.csv
â”œâ”€â”€ 0001_11.csv
â”œâ”€â”€ 0002_11.csv
â””â”€â”€ ...
```

**í…œí”Œë¦¿ íŒŒì¼ ì˜ˆì‹œ:**
| Logic ID | Folder ID | Logic Name | Description | Note |
|----------|-----------|------------|-------------|------|
| 0000_11  | FOLDER_A  | Main Logic | ë©”ì¸ ë¡œì§   | ...  |
| 0001_11  | FOLDER_A  | Sub Logic  | ì„œë¸Œ ë¡œì§   | ...  |

---

### 2. API í˜¸ì¶œ

**Endpoint:**
```
POST /programs/upload
```

**Request (Form Data):**
```
pgm_name: "Test Program"           (í•„ìˆ˜)
create_user: "admin"               (í•„ìˆ˜)
pgm_ladder_zip_file: [íŒŒì¼]        (í•„ìˆ˜)
pgm_template_file: [íŒŒì¼]          (í•„ìˆ˜)
pgm_version: "1.0"                 (ì„ íƒ)
description: "í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨"     (ì„ íƒ)
notes: "ë¹„ê³ "                      (ì„ íƒ)
```

**cURL ì˜ˆì‹œ:**
```bash
curl -X POST "http://localhost:8000/programs/upload" \
  -F "pgm_name=Test Program" \
  -F "create_user=admin" \
  -F "pgm_ladder_zip_file=@ladder_files.zip" \
  -F "pgm_template_file=@template.xlsx" \
  -F "pgm_version=1.0" \
  -F "description=í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨"
```

**Python ì˜ˆì‹œ:**
```python
import requests

url = "http://localhost:8000/programs/upload"

files = {
    'pgm_ladder_zip_file': ('ladder_files.zip', open('ladder_files.zip', 'rb'), 'application/zip'),
    'pgm_template_file': ('template.xlsx', open('template.xlsx', 'rb'), 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
}

data = {
    'pgm_name': 'Test Program',
    'create_user': 'admin',
    'pgm_version': '1.0',
    'description': 'í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨'
}

response = requests.post(url, files=files, data=data)
print(response.json())
```

---

### 3. ì‘ë‹µ í™•ì¸

**ì„±ê³µ ì‘ë‹µ (201 Created):**
```json
{
  "pgm_id": "PGM_1",
  "pgm_name": "Test Program",
  "pgm_version": "1.0",
  "description": "í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨",
  "create_user": "admin",
  "create_dt": "2025-11-06T10:30:00",
  "validation_result": {
    "validation_passed": true,
    "matched_files": ["0000_11.csv", "0001_11.csv"],
    "missing_files": [],
    "unexpected_files": []
  },
  "saved_files": {
    "ladder_csv_documents": [...],
    "template_document": {...}
  },
  "summary": {
    "total_ladder_files": 2,
    "template_parsed": true,
    "template_row_count": 2
  },
  "message": "í”„ë¡œê·¸ë¨ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
}
```

**ì‹¤íŒ¨ ì‘ë‹µ (400 Bad Request):**
```json
{
  "code": "INVALID_DATA_FORMAT",
  "message": "í•„ìˆ˜ ë ˆë” íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 0000_11.csv",
  "timestamp": "2025-11-06T10:30:00"
}
```

---

## ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

### Q1: PGM_IDëŠ” ì–´ë–»ê²Œ ìƒì„±ë˜ë‚˜ìš”?
A: ì„œë²„ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. PGM_1, PGM_2, PGM_3 ... ìˆœìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤.

### Q2: í…œí”Œë¦¿ì— ì—†ëŠ” íŒŒì¼ì´ ZIPì— ìˆìœ¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
A: ìë™ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤. ê²½ê³  ì—†ì´ í•„ìš”í•œ íŒŒì¼ë§Œ ì €ì¥ë©ë‹ˆë‹¤.

### Q3: íŒŒì¼ í¬ê¸° ì œí•œì„ ë³€ê²½í•  ìˆ˜ ìˆë‚˜ìš”?
A: ë„¤, í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.

### Q4: ì—…ë¡œë“œì— ì‹¤íŒ¨í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
A: ëª¨ë“  ë³€ê²½ì‚¬í•­ì´ ë¡¤ë°±ë©ë‹ˆë‹¤. ì €ì¥ëœ íŒŒì¼ë„ ìë™ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤.

### Q5: ë™ì‹œì— ì—¬ëŸ¬ í”„ë¡œê·¸ë¨ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆë‚˜ìš”?
A: ë„¤, ìµœëŒ€ 5ê°œê¹Œì§€ ë™ì‹œ ì—…ë¡œë“œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ë¬¸ì œ í•´ê²°

### íŒŒì¼ íƒ€ì… ì˜¤ë¥˜
**ì¦ìƒ:** "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹" ì—ëŸ¬  
**í•´ê²°:** 
- ë ˆë” íŒŒì¼ì€ ZIPìœ¼ë¡œ ì••ì¶•
- í…œí”Œë¦¿ì€ XLSX ë˜ëŠ” XLS ì‚¬ìš©

### íŒŒì¼ í¬ê¸° ì´ˆê³¼
**ì¦ìƒ:** "íŒŒì¼ í¬ê¸° ì´ˆê³¼" ì—ëŸ¬  
**í•´ê²°:**
- ZIP íŒŒì¼: 100MB ì´í•˜ë¡œ ì¤„ì´ê¸°
- í…œí”Œë¦¿: 10MB ì´í•˜ë¡œ ì¤„ì´ê¸°

### í•„ìˆ˜ íŒŒì¼ ëˆ„ë½
**ì¦ìƒ:** "í•„ìˆ˜ ë ˆë” íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤" ì—ëŸ¬  
**í•´ê²°:**
- í…œí”Œë¦¿ì˜ Logic IDì™€ ZIP íŒŒì¼ëª… ì¼ì¹˜ í™•ì¸
- ëŒ€ì†Œë¬¸ì êµ¬ë¶„ í™•ì¸

### í…œí”Œë¦¿ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½
**ì¦ìƒ:** "í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤" ì—ëŸ¬  
**í•´ê²°:**
- Logic ID, Folder ID, Logic Name ì»¬ëŸ¼ í™•ì¸
- ì² ì ë° ë„ì–´ì“°ê¸° í™•ì¸
```

---

### ğŸ“Š ë¬¸ì„œí™” ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | í˜„ì¬ | ëª©í‘œ | ìš°ì„ ìˆœìœ„ |
|------|------|------|----------|
| Swagger ì˜ˆì œ | âŒ | âœ… | ë†’ìŒ |
| ì—ëŸ¬ ì½”ë“œ ë¬¸ì„œ | âŒ | âœ… | ë†’ìŒ |
| ì‚¬ìš©ì ê°€ì´ë“œ | âŒ | âœ… | ì¤‘ê°„ |
| API ì•„í‚¤í…ì²˜ | âŒ | âœ… | ì¤‘ê°„ |
| í™˜ê²½ë³€ìˆ˜ ë¬¸ì„œ | âœ… | âœ… | ì™„ë£Œ |
| ì½”ë“œ ì£¼ì„ | 70% | 90% | ë‚®ìŒ |

**ì˜ˆìƒ ì‘ì—… ì‹œê°„:** 4-5ì‹œê°„

---

## ì¶”ê°€ ê°œì„  ì œì•ˆ

### 4. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ê°•í™”

**í˜„ì¬ ë¬¸ì œ:**
- ë¡œê·¸ ë ˆë²¨ ì¼ê´€ì„± ë¶€ì¡±
- ì¤‘ìš” ì§€í‘œ ì¶”ì  ë¯¸í¡
- ì—ëŸ¬ ì•Œë¦¼ ì—†ìŒ

**ê°œì„  ë°©ì•ˆ:**

**êµ¬ì¡°í™”ëœ ë¡œê¹…:**
```python
import structlog

logger = structlog.get_logger()

# Before
logger.info(f"âœ… [Step 1] ë ˆë” ZIP íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {filename}")

# After
logger.info(
    "ladder_zip_validation_success",
    step=1,
    filename=filename,
    file_size=file_size,
    pgm_id=pgm_id,
    elapsed_time_ms=elapsed_ms
)
```

**ì£¼ìš” ì§€í‘œ ì¶”ì :**
```python
from prometheus_client import Counter, Histogram, Gauge

# ì—…ë¡œë“œ ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´í„°
upload_success_counter = Counter(
    'program_upload_success_total',
    'Total successful program uploads'
)

upload_failure_counter = Counter(
    'program_upload_failure_total',
    'Total failed program uploads',
    ['error_type']  # ì—ëŸ¬ ìœ í˜•ë³„
)

# ì²˜ë¦¬ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
upload_duration_histogram = Histogram(
    'program_upload_duration_seconds',
    'Program upload processing time',
    buckets=[0.5, 1.0, 2.0, 4.0, 8.0, 16.0]
)

# íŒŒì¼ í¬ê¸° ê²Œì´ì§€
file_size_gauge = Gauge(
    'program_upload_file_size_bytes',
    'Uploaded file size in bytes'
)
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„:** 3ì‹œê°„

---

### 5. ì—ëŸ¬ ë³µêµ¬ ì „ëµ

**í˜„ì¬ ë¬¸ì œ:**
- ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ì—†ìŒ
- ë¶€ë¶„ ì‹¤íŒ¨ ë³µêµ¬ ì–´ë ¤ì›€

**ê°œì„  ë°©ì•ˆ:**

**ìë™ ì¬ì‹œë„ (Exponential Backoff):**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def save_file_with_retry(self, file_path: Path, content: bytes):
    """
    íŒŒì¼ ì €ì¥ ì¬ì‹œë„
    - 1ì°¨ ì‹¤íŒ¨: 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
    - 2ì°¨ ì‹¤íŒ¨: 4ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
    - 3ì°¨ ì‹¤íŒ¨: ìµœì¢… ì‹¤íŒ¨
    """
    try:
        file_path.write_bytes(content)
    except OSError as e:
        logger.warning(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨, ì¬ì‹œë„: {e}")
        raise
```

**ë¶€ë¶„ ë³µêµ¬:**
```python
def upload_program_with_partial_recovery(self, ...):
    """
    ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ì‹œë„
    """
    try:
        # Phase 1-3 ì‹¤í–‰
        ...
    except TemplateParsingError:
        # í…œí”Œë¦¿ íŒŒì‹±ë§Œ ì‹¤íŒ¨ â†’ ë‹¤ë¥¸ ì‘ì—…ì€ ìœ ì§€
        logger.warning("í…œí”Œë¦¿ íŒŒì‹± ì‹¤íŒ¨, ë ˆë” íŒŒì¼ì€ ì €ì¥ë¨")
        
        # ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜
        return {
            'pgm_id': pgm_id,
            'status': 'partial_success',
            'message': 'ë ˆë” íŒŒì¼ ì €ì¥ ì™„ë£Œ, í…œí”Œë¦¿ íŒŒì‹± ì‹¤íŒ¨',
            'saved_files': saved_files
        }
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„:** 2ì‹œê°„

---

### 6. ë³´ì•ˆ ê°•í™”

**í˜„ì¬ ë¬¸ì œ:**
- íŒŒì¼ ë‚´ìš© ê²€ì¦ ë¯¸í¡ (ì•…ì„± íŒŒì¼)
- ì—…ë¡œë“œ ì†ë„ ì œí•œ ì—†ìŒ
- íŒŒì¼ëª… ê²€ì¦ ë¯¸í¡ (ê²½ë¡œ ìˆœíšŒ ê³µê²©)

**ê°œì„  ë°©ì•ˆ:**

**íŒŒì¼ ë‚´ìš© ê²€ì¦:**
```python
import magic

def validate_file_content(self, file: UploadFile):
    """
    ì‹¤ì œ íŒŒì¼ ë‚´ìš© ê²€ì¦ (MIME ìŠ¤ë‹ˆí•‘)
    - í™•ì¥ìì™€ ì‹¤ì œ ë‚´ìš© ì¼ì¹˜ í™•ì¸
    - ì•…ì„± íŒŒì¼ íƒì§€
    """
    content = file.file.read(8192)  # ì²˜ìŒ 8KB ì½ê¸°
    file.file.seek(0)
    
    # ì‹¤ì œ MIME íƒ€ì… í™•ì¸
    actual_mime = magic.from_buffer(content, mime=True)
    
    if file.filename.endswith('.zip'):
        if actual_mime != 'application/zip':
            raise HandledException(
                ResponseCode.DOCUMENT_INVALID_FILE_TYPE,
                msg="ZIP íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤"
            )
```

**ì†ë„ ì œí•œ (Rate Limiting):**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post("/programs/upload")
@limiter.limit("5/minute")  # 1ë¶„ì— 5íšŒ ì œí•œ
async def upload_program_files(...):
    ...
```

**íŒŒì¼ëª… ê²€ì¦:**
```python
import re
from pathlib import PurePosixPath

def sanitize_filename(self, filename: str) -> str:
    """
    íŒŒì¼ëª… ê²€ì¦ ë° ì •ë¦¬
    - ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
    - íŠ¹ìˆ˜ë¬¸ì ì œê±°
    """
    # ê²½ë¡œ ìˆœíšŒ ì‹œë„ ì°¨ë‹¨
    if '..' in filename or '/' in filename or '\\' in filename:
        raise HandledException(
            ResponseCode.INVALID_DATA_FORMAT,
            msg="ì˜ëª»ëœ íŒŒì¼ëª…"
        )
    
    # ì•ˆì „í•œ íŒŒì¼ëª…ë§Œ í—ˆìš©
    safe_filename = re.sub(r'[^\w\s.-]', '', filename)
    return safe_filename
```

**ì˜ˆìƒ ì‘ì—… ì‹œê°„:** 3ì‹œê°„

---

## ìš°ì„ ìˆœìœ„ ë° ë¡œë“œë§µ

### ğŸ“Š ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤

```
ë†’ì€ ì˜í–¥ â†‘
â”‚
â”‚  [Phase 6: ì„±ëŠ¥ ìµœì í™”]    [í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±]
â”‚        (7ì‹œê°„)                  (8ì‹œê°„)
â”‚         ìš°ì„ ìˆœìœ„ 1                ìš°ì„ ìˆœìœ„ 2
â”‚
â”‚
â”‚  [ë³´ì•ˆ ê°•í™”]              [API ë¬¸ì„œ ë³´ê°•]
â”‚    (3ì‹œê°„)                   (5ì‹œê°„)
â”‚   ìš°ì„ ìˆœìœ„ 4                 ìš°ì„ ìˆœìœ„ 3
â”‚
â”‚
â”‚  [ë¡œê¹… ê°•í™”]              [ì—ëŸ¬ ë³µêµ¬]
â”‚    (3ì‹œê°„)                   (2ì‹œê°„)
â”‚   ìš°ì„ ìˆœìœ„ 5                 ìš°ì„ ìˆœìœ„ 6
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> ë†’ì€ ê¸´ê¸‰ë„
```

### ğŸ“… ê¶Œì¥ ì‘ì—… ìˆœì„œ

#### 1ì°¨: í•µì‹¬ ê¸°ëŠ¥ ì•ˆì •í™” (15ì‹œê°„)
```
Week 1: Phase 6 (ì„±ëŠ¥ ìµœì í™”) - 7ì‹œê°„
Week 2: í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± - 8ì‹œê°„
```

#### 2ì°¨: ì‚¬ìš©ì„± ê°œì„  (8ì‹œê°„)
```
Week 3: API ë¬¸ì„œ ë³´ê°• - 5ì‹œê°„
Week 4: ë³´ì•ˆ ê°•í™” - 3ì‹œê°„
```

#### 3ì°¨: ìš´ì˜ ê°œì„  (5ì‹œê°„, ì„ íƒì‚¬í•­)
```
Week 5: ë¡œê¹… ê°•í™” - 3ì‹œê°„
Week 6: ì—ëŸ¬ ë³µêµ¬ - 2ì‹œê°„
```

### ğŸ’° ROI ë¶„ì„

| ì‘ì—… | íˆ¬ì ì‹œê°„ | ì˜ˆìƒ íš¨ê³¼ | ROI |
|------|----------|----------|-----|
| ì„±ëŠ¥ ìµœì í™” | 7ì‹œê°„ | ì²˜ë¦¬ ì‹œê°„ 42% ê°ì†Œ | ë§¤ìš° ë†’ìŒ |
| í†µí•© í…ŒìŠ¤íŠ¸ | 8ì‹œê°„ | ë²„ê·¸ ì¡°ê¸° ë°œê²¬, ì•ˆì •ì„± í–¥ìƒ | ë†’ìŒ |
| API ë¬¸ì„œ | 5ì‹œê°„ | ì‚¬ìš©ì ë¬¸ì˜ 50% ê°ì†Œ | ë†’ìŒ |
| ë³´ì•ˆ ê°•í™” | 3ì‹œê°„ | ë³´ì•ˆ ìœ„í—˜ 90% ê°ì†Œ | ë†’ìŒ |
| ë¡œê¹… ê°•í™” | 3ì‹œê°„ | ë¬¸ì œ í•´ê²° ì‹œê°„ 50% ê°ì†Œ | ì¤‘ê°„ |
| ì—ëŸ¬ ë³µêµ¬ | 2ì‹œê°„ | ê°€ìš©ì„± í–¥ìƒ | ì¤‘ê°„ |

---

## ğŸ“ ìš”ì•½

### ì¦‰ì‹œ ì‹œì‘ ê¶Œì¥ (ë†’ì€ ìš°ì„ ìˆœìœ„)

1. **Phase 6: ì„±ëŠ¥ ìµœì í™”** (7ì‹œê°„)
   - ê°€ì¥ í° ì„íŒ©íŠ¸
   - ì‚¬ìš©ì ê²½í—˜ ì§ì ‘ ê°œì„ 
   - í™•ì¥ì„± í™•ë³´

2. **í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±** (8ì‹œê°„)
   - ì•ˆì •ì„± ë³´ì¥
   - íšŒê·€ ë°©ì§€
   - ë¦¬íŒ©í† ë§ ì‹ ë¢°ë„ í–¥ìƒ

3. **API ë¬¸ì„œ ë³´ê°•** (5ì‹œê°„)
   - ì‚¬ìš©ì í¸ì˜ì„±
   - ì§€ì› ë¹„ìš© ì ˆê°
   - ì˜¨ë³´ë”© ì‹œê°„ ë‹¨ì¶•

### ì ì§„ì  ê°œì„  (ì¤‘ê°„ ìš°ì„ ìˆœìœ„)

4. **ë³´ì•ˆ ê°•í™”** (3ì‹œê°„)
   - ë¦¬ìŠ¤í¬ ì™„í™”
   - í”„ë¡œë•ì…˜ ì¤€ë¹„

5. **ë¡œê¹… ê°•í™”** (3ì‹œê°„)
   - ìš´ì˜ íš¨ìœ¨ì„±
   - ë¬¸ì œ í•´ê²° ì†ë„

6. **ì—ëŸ¬ ë³µêµ¬** (2ì‹œê°„)
   - ì•ˆì •ì„± í–¥ìƒ
   - ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

**ì´ ì˜ˆìƒ ì‹œê°„: 28ì‹œê°„ (ì•½ 3.5ì¼)**

---

ê¶ê¸ˆí•˜ì‹  ë¶€ë¶„ì´ë‚˜ íŠ¹ì • í•­ëª©ì— ëŒ€í•´ ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š